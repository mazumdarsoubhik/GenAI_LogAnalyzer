{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ccd61b8",
   "metadata": {},
   "source": [
    "## Install Cohere Library\n",
    "Signup to https://dashboard.cohere.com/ and get your Cohere API key from https://dashboard.cohere.com/api-keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e897938f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install cohere"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746ee23d",
   "metadata": {},
   "source": [
    "## Cohere Library Heartbeat Check\n",
    "Pypi documentation: https://pypi.org/project/cohere/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f50af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cohere\n",
    "MY_API_KEY=\"<PUT YOUR API KEY>\"  # Put your API key copied from Cohere dashboard - https://dashboard.cohere.com/api-keys\n",
    "\n",
    "co = cohere.Client(\n",
    "    api_key=MY_API_KEY,\n",
    ")\n",
    "\n",
    "chat = co.chat(\n",
    "    message=\"Hello world!\",\n",
    "    model=\"command-r-plus\"\n",
    ")\n",
    "\n",
    "print(chat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273f64cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = co.chat_stream(\n",
    "    message=\"What is my name?\",\n",
    "    conversation_id=\"ABC123\"\n",
    ")\n",
    "\n",
    "for event in stream:\n",
    "    if event.event_type == \"text-generation\":\n",
    "        print(event.text, end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e3c022",
   "metadata": {},
   "source": [
    "## Make LLM Object Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6873ec55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, string\n",
    "    \n",
    "class CohereLLMAPI:\n",
    "    _name=\"Cohere\"\n",
    "    _models=[\"command\", \"command-r-plus\"]\n",
    "    _model=None\n",
    "    _API_KEY=None\n",
    "    _instance=None\n",
    "    _chat_id=None\n",
    "    \n",
    "    def __init__(self, KEY: str, model=\"command-r-plus\"):\n",
    "        self._API_KEY=KEY\n",
    "        try:\n",
    "            # Validate and fixate LLM model\n",
    "            if model not in self._models: # If model belongs to Cohere list\n",
    "                raise ValueError(f\"\\n\\tInvalid LLM model: {model}\")\n",
    "            self._model=model\n",
    "            \n",
    "            # Generate Chat ID - Randomised\n",
    "            self._chat_id = ''.join(random.choices(string.ascii_letters, k=10))\n",
    "            \n",
    "            # Initiate API\n",
    "            self._instance=cohere.Client(api_key=self._API_KEY)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed connecting to {self._name} API: {e}\")\n",
    "    \n",
    "    def change_key(self, new_KEY):\n",
    "        self._API_KEY=new_KEY\n",
    "        self._instance=cohere.Client(api_key=self._API_KEY)\n",
    "    \n",
    "    def text_generate(self, input_text):\n",
    "        return co.chat(\n",
    "            message=input_text,\n",
    "            model=self._model).text\n",
    "    \n",
    "    def chat_stream_print(self, user_message):\n",
    "        stream = co.chat_stream(\n",
    "            message=user_message,\n",
    "            conversation_id=self._chat_id\n",
    "        )\n",
    "\n",
    "        for event in stream:\n",
    "            if event.event_type == \"text-generation\":\n",
    "                print(event.text, end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8008aab7",
   "metadata": {},
   "source": [
    "## Testing: Text Generation\n",
    "This function is only used to generate text. It does not remember the history of chat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef35f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_api = CohereLLMAPI(MY_API_KEY) # Initiate with API Key\n",
    "\n",
    "while True:\n",
    "    msg = input(\"> \")\n",
    "    if msg == \"END\":\n",
    "        break\n",
    "    print(llm_api.text_generate(msg))\n",
    "    print(f\"-- Type END to exit-- (Close this block to execute others)\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef32fa3",
   "metadata": {},
   "source": [
    "## Testing: Chat with History\n",
    "This chat function remembers the history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be40b1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_api = CohereLLMAPI(MY_API_KEY) # Initiate with API Key\n",
    "\n",
    "while True:\n",
    "    msg = input(\"> \")\n",
    "    if msg == \"END\":\n",
    "        break\n",
    "    print(\"\\nAssistant:\")\n",
    "    print(llm_api.chat_stream_print(msg))\n",
    "    print(f\"-- Type END to exit-- (Close this block to execute others)\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c002fb2",
   "metadata": {},
   "source": [
    "## Testing: Chat with Initial Prompt\n",
    "With this method you can augment the chatbot to behave in a certain way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c10600",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "llm_api = CohereLLMAPI(MY_API_KEY) # Initiate with API Key\n",
    "\n",
    "system_prompt=\"\"\"\n",
    "You are Aime, a knowledgeable virtual assistant specializing in Australian policy regulations. Your primary focus is to provide accurate and up-to-date information on regulations from the Australian Prudential Regulation Authority (APRA) and other relevant regulatory bodies.\n",
    "\n",
    "When users ask about Australian policy regulations, such as APRA guidelines, regulatory updates, or compliance requirements, respond with clear, concise information and guidance. Provide insights into regulatory processes, recent changes, and how they impact various sectors.\n",
    "\n",
    "For example:\n",
    "- If a user asks about recent APRA guidelines, provide a summary of the latest guidelines, their purpose, and their implications for businesses.\n",
    "- If a user inquires about compliance requirements, detail the necessary steps or documentation needed to comply with APRA regulations.\n",
    "\n",
    "Remember, your responses should be informative, accurate, and relevant to Australian regulatory policies.\n",
    "\n",
    "Briefly introduce yourself and provide a bullet-point list of your capabilities.\n",
    "\"\"\"\n",
    "filter_prompt=\"\"\"\n",
    "Instruction for Responses:\n",
    "- Focus exclusively on policies: Your responses should be limited to providing information about Australian policies, regulations, and related guidelines.\n",
    "- No unrelated information: Do not answer questions or provide information about topics that are not directly related to policies, regulations, or compliance issues. This includes general knowledge, personal opinions, or unrelated technical or non-policy-related topics.\n",
    "- Clarify when uncertain: If a query does not pertain to policy-related matters, politely inform the user that your expertise is focused on policies and suggest that they ask a question related to that domain.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "print(llm_api.chat_stream_print(system_prompt))\n",
    "\n",
    "while True:\n",
    "    msg = input(\"> \")\n",
    "    if msg == \"END\":\n",
    "        break\n",
    "    print(\"\\nAssistant:\")\n",
    "    print(llm_api.chat_stream_print(filter_prompt + f\"\\nUser:\\n\" + msg))\n",
    "    print(f\"-- Type END to exit-- (Close this block to execute others)\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc46724",
   "metadata": {},
   "source": [
    "## Thalaivaa: Your Movie Maestro\n",
    "Crafting Perfect Picks for Your Next Movie Night!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be020d2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "llm_api = CohereLLMAPI(MY_API_KEY) # Initiate with API Key\n",
    "\n",
    "system_prompt=\"\"\"\n",
    "You are Thalaivaa, a sophisticated virtual movie recommender with an extensive knowledge of films, genres, actors, and directors. Your primary role is to suggest movies based on user preferences, including genre, mood, or specific actors and directors.\n",
    "\n",
    "When users ask for movie recommendations, respond with personalized suggestions that match their criteria. Provide brief descriptions of the movies and highlight why they might enjoy them based on their preferences.\n",
    "\n",
    "For example:\n",
    "- If a user is in the mood for a comedy, suggest movies in that genre and provide a short synopsis of each.\n",
    "- If a user mentions they like a particular actor, recommend films featuring that actor and explain why the user might like them.\n",
    "- If a user is looking for a movie similar to one they've enjoyed, suggest films with similar themes or styles.\n",
    "\n",
    "Remember, your responses should be engaging, relevant, and tailored to the user's interests in movies.\n",
    "\n",
    "Briefly introduce yourself and provide a bullet-point list of your capabilities.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "filter_prompt=\"\"\"\n",
    "Instruction for Responses:\n",
    "- Focus on movie suggestions: Your responses should be centered around recommending movies based on user preferences, such as genre, mood, actors, or directors.\n",
    "- Avoid unrelated topics: Do not provide information about topics that are not related to movies or film recommendations. This includes general knowledge, personal opinions, or non-movie-related queries.\n",
    "- Address irrelevant questions directly: If a user asks a question that doesn't relate to movies or film recommendations, clearly inform them that you can only help with movie suggestions. Use a straightforward or slightly sarcastic tone to convey this. For example:\n",
    "  - Direct: \"I can only help with movie recommendations. Let's stick to that, shall we?\"\n",
    "  - Sarcastic: \"Oh, I wish I could help with that, but Iâ€™m strictly here for movie magic!\"\n",
    "- Clarify when uncertain: Politely guide the user back to asking about movies if their query isn't related.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "print(llm_api.chat_stream_print(system_prompt))\n",
    "\n",
    "while True:\n",
    "    msg = input(\"> \")\n",
    "    if msg == \"END\":\n",
    "        break\n",
    "    print(\"\\nAssistant:\")\n",
    "    print(llm_api.chat_stream_print(filter_prompt + f\"\\nUser:\\n\" + msg))\n",
    "    print(f\"-- Type END to exit-- (Close this block to execute others)\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f421bf",
   "metadata": {},
   "source": [
    "## The End\n",
    "All the best for the Hackathon!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
